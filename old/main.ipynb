{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทุก event ต้องนำหน้าด้วย await ให้หมด "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playwright in ./.venv/lib/python3.12/site-packages (1.45.0)\n",
      "Requirement already satisfied: html5lib in ./.venv/lib/python3.12/site-packages (1.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: xlrd in ./.venv/lib/python3.12/site-packages (2.0.1)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.12/site-packages (5.2.2)\n",
      "Requirement already satisfied: papermill in ./.venv/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: greenlet==3.0.3 in ./.venv/lib/python3.12/site-packages (from playwright) (3.0.3)\n",
      "Requirement already satisfied: pyee==11.1.0 in ./.venv/lib/python3.12/site-packages (from playwright) (11.1.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from pyee==11.1.0->playwright) (4.12.2)\n",
      "Requirement already satisfied: six>=1.9 in ./.venv/lib/python3.12/site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.12/site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from papermill) (8.1.7)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from papermill) (6.0.1)\n",
      "Requirement already satisfied: nbformat>=5.2.0 in ./.venv/lib/python3.12/site-packages (from papermill) (5.10.4)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in ./.venv/lib/python3.12/site-packages (from papermill) (0.10.0)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in ./.venv/lib/python3.12/site-packages (from papermill) (4.66.4)\n",
      "Requirement already satisfied: entrypoints in ./.venv/lib/python3.12/site-packages (from papermill) (0.4)\n",
      "Requirement already satisfied: tenacity>=5.0.2 in ./.venv/lib/python3.12/site-packages (from papermill) (8.5.0)\n",
      "Requirement already satisfied: ansicolors in ./.venv/lib/python3.12/site-packages (from papermill) (1.1.8)\n",
      "Requirement already satisfied: aiohttp>=3.9.0 in ./.venv/lib/python3.12/site-packages (from papermill) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->papermill) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->papermill) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->papermill) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->papermill) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.12/site-packages (from aiohttp>=3.9.0->papermill) (1.9.4)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.12/site-packages (from nbclient>=0.2.0->papermill) (8.6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from nbclient>=0.2.0->papermill) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.4 in ./.venv/lib/python3.12/site-packages (from nbclient>=0.2.0->papermill) (5.14.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.12/site-packages (from nbformat>=5.2.0->papermill) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./.venv/lib/python3.12/site-packages (from nbformat>=5.2.0->papermill) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (6.4.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->nbclient>=0.2.0->papermill) (4.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install playwright html5lib requests beautifulsoup4 xlrd lxml papermill "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from diw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from playwright.async_api import async_playwright\n",
    "# from datetime import datetime\n",
    "\n",
    "# area_skip = ['กทม. และภาคกลาง','ภาคเหนือ']\n",
    "# province_skip = ['จ.นครราชสีมา','จ.บุรีรัมย์','จ.สุรินทร์','จ.ศรีสะเกษ']\n",
    "\n",
    "# async def main():\n",
    "#     start_time = datetime.now()\n",
    "#     broken_excel_file = []\n",
    "#     async with async_playwright() as playwright:\n",
    "#         # Launch a browser\n",
    "#         browser = await playwright.chromium.launch(headless=False) # headless=False : ให้หน้า browser ขึ้นมาเวลารันเป็นเวลา slow_mo=500 : pop-up ขึ้นมาเป็นเวลา 0.5 secs\n",
    "#         # Create a new page\n",
    "#         page = await browser.new_page()\n",
    "\n",
    "#         target_url = 'https://userdb.diw.go.th/factoryPublic/tumbol.asp'\n",
    "\n",
    "#         await page.goto(target_url)\n",
    "\n",
    "#         area_arr = []\n",
    "\n",
    "#         area = await page.locator('//a').all()\n",
    "\n",
    "#         for a in area:\n",
    "#             area_arr.append(await a.text_content())\n",
    "\n",
    "#         # Loop area\n",
    "#         for a in area_arr:\n",
    "#             if a not in area_skip:\n",
    "#                 await page.locator(f\"//a[text()='{a}']\").click()\n",
    "\n",
    "#                 # await page.reload()\n",
    "\n",
    "#                 province_arr = []\n",
    "\n",
    "#                 province = await page.locator(\"//a[contains(text(),'จ.')]\").all()\n",
    "\n",
    "#                 for p in province:\n",
    "#                     province_arr.append(await p.text_content())\n",
    "\n",
    "#                 # Loop province\n",
    "#                 for p in province_arr:\n",
    "#                     if p not in province_skip:\n",
    "#                         await page.locator(f\"//a[text()='{p}']\").click()\n",
    "\n",
    "#                         # await page.reload()\n",
    "\n",
    "#                         district_arr = []\n",
    "\n",
    "#                         district = await page.locator(\"//a[contains(text(),'อ.')]\").all()\n",
    "\n",
    "#                         for d in district:\n",
    "#                             district_arr.append(await d.text_content())\n",
    "\n",
    "#                         # Loop district\n",
    "#                         for d in district_arr:\n",
    "#                             if 'กิ่งอำเภอ' not in d:\n",
    "#                                 await page.locator(f\"//a[text()='{d}']\").click()\n",
    "\n",
    "#                                 # await page.reload()\n",
    "\n",
    "#                                 # Start waiting for the download\n",
    "#                                 async with page.expect_download() as download_info:\n",
    "#                                     # Perform the action that initiates download\n",
    "#                                         await page.locator(f\"//a[contains(text(),'download')]\").click()\n",
    "\n",
    "#                                         download = await download_info.value\n",
    "\n",
    "#                                         # Wait for the download process to complete and save the downloaded file somewhere\n",
    "#                                         await download.save_as(f\"./diw/{a}/{download.suggested_filename}\")\n",
    "#                                         await page.reload()\n",
    "#                             else:\n",
    "#                                 broken_excel_file.append([a,p,d])\n",
    "#                                 await page.reload()  # Skip to the next download\n",
    "\n",
    "#         await browser.close() \n",
    "\n",
    "#         end_time = datetime.now()\n",
    "#         diff_time = end_time - start_time\n",
    "#         print(diff_time)\n",
    "\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from playwright.async_api import async_playwright\n",
    "# from datetime import datetime\n",
    "\n",
    "# async def main():\n",
    "#     start_time = datetime.now()\n",
    "#     broken_excel_file = []\n",
    "#     async with async_playwright() as playwright:\n",
    "#         # Launch a browser\n",
    "#         browser = await playwright.chromium.launch(headless=False) # headless=False : ให้หน้า browser ขึ้นมาเวลารันเป็นเวลา slow_mo=500 : pop-up ขึ้นมาเป็นเวลา 0.5 secs\n",
    "#         # Create a new page\n",
    "#         page = await browser.new_page()\n",
    "\n",
    "#         target_url = 'https://userdb.diw.go.th/factoryPublic/tumbol.asp'\n",
    "\n",
    "#         await page.goto(target_url)\n",
    "\n",
    "#         await page.locator(f\"//a[text()='ภาคตะวันออกเฉียงเหนือ']\").click()\n",
    "\n",
    "#         await page.locator(f\"//a[text()='จ.นครราชสีมา']\").click()\n",
    "\n",
    "#         await page.locator(f\"//a[text()='อ.เมืองนครราชสีมา']\").click()\n",
    "\n",
    "#         # Start waiting for the download\n",
    "#         async with page.expect_download() as download_info:\n",
    "#             # Perform the action that initiates download\n",
    "#                 await page.locator(f\"//a[contains(text(),'download')]\").click()\n",
    "\n",
    "#                 download = await download_info.value\n",
    "\n",
    "#                 # Wait for the download process to complete and save the downloaded file somewhere\n",
    "#                 await download.save_as(f\"./diw/ภาคตะวันออกเฉียงเหนือ/{download.suggested_filename}\")\n",
    "#                 await page.reload()\n",
    "                \n",
    "#         await browser.close() \n",
    "\n",
    "#         end_time = datetime.now()\n",
    "#         diff_time = end_time - start_time\n",
    "#         print(diff_time)\n",
    "\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append all diw datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# start_time = datetime.now()\n",
    "\n",
    "# # Replace \"path/to/your/directory\" with the actual path\n",
    "# diw_path = \"./diw\"\n",
    "\n",
    "# # Get list of entries in the directory\n",
    "# entries = os.listdir(diw_path)\n",
    "\n",
    "# # Filter for directories (optional)\n",
    "# folders = [entry for entry in entries if os.path.isdir(os.path.join(diw_path, entry))]\n",
    "\n",
    "# dfs = []\n",
    "\n",
    "# output_path_name = 'all'\n",
    "# df_output_path = f\"./diw/{output_path_name}\"\n",
    "# file_output_name = 'diw_client.xlsx'\n",
    "\n",
    "# for folder in folders:\n",
    "#     diw_folder_path = os.path.join(diw_path, folder)\n",
    "#     diw_datas = os.listdir(diw_folder_path)\n",
    "#     for data in diw_datas:\n",
    "#         if data != output_path_name:\n",
    "#             diw_data_path = os.path.join(diw_folder_path, data)\n",
    "#             df = pd.read_excel(diw_data_path)\n",
    "#             df = df.iloc[:-2,:]\n",
    "#             df['Area'] = [folder]*len(df)\n",
    "#             dfs.append(df)\n",
    "\n",
    "# df_concat = pd.concat(dfs,axis=0)\n",
    "\n",
    "# # Create the directory if it doesn't exist\n",
    "# os.makedirs(df_output_path, exist_ok=True)  # Handles existing directories gracefully\n",
    "\n",
    "# # Save the DataFrame to an XLS file\n",
    "# df_concat.to_excel(os.path.join(df_output_path, file_output_name), index=False)\n",
    "\n",
    "# end_time = datetime.now()\n",
    "# diff_time = end_time - start_time\n",
    "# print(diff_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run ข้ามวัน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare before extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/Desktop/P.Tech/Find Leads/.venv/lib/python3.12/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>เลขทะเบียนโรงงาน</th>\n",
       "      <th>ชื่อโรงงาน</th>\n",
       "      <th>ผู้ประกอบการ</th>\n",
       "      <th>ประกอบกิจการ</th>\n",
       "      <th>เลขที่</th>\n",
       "      <th>หมู่</th>\n",
       "      <th>ซอย</th>\n",
       "      <th>ถนน</th>\n",
       "      <th>ตำบล</th>\n",
       "      <th>อำเภอ</th>\n",
       "      <th>จังหวัด</th>\n",
       "      <th>ไปรษณีย์</th>\n",
       "      <th>โทรศัพท์</th>\n",
       "      <th>ประเภท</th>\n",
       "      <th>เงินทุน</th>\n",
       "      <th>คนงาน</th>\n",
       "      <th>แรงม้า</th>\n",
       "      <th>TSIC</th>\n",
       "      <th>เลขทะเบียนเดิม</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20600006925518</td>\n",
       "      <td>ห้างหุ้นส่วนจำกัด บุญชูคอนกรีตผสมเสร็จ</td>\n",
       "      <td>บุญชูคอนกรีต</td>\n",
       "      <td>ผลิตคอนกรีตผสมเสร็จ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ชุมตาบง</td>\n",
       "      <td>ชุมตาบง</td>\n",
       "      <td>นครสวรรค์</td>\n",
       "      <td>60150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5801</td>\n",
       "      <td>6500000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>23953.0</td>\n",
       "      <td>จ3-58(1)-69/51นว</td>\n",
       "      <td>กทม. และภาคกลาง</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10140100125188</td>\n",
       "      <td>บริษัท โนเบิลวู้ด จำกัด</td>\n",
       "      <td>โนเบิลวู้ด</td>\n",
       "      <td>ผลิตไม้วีเนียร์</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>เข้าโรงงานกระดาษบางปะอิน</td>\n",
       "      <td>บ้านเลน</td>\n",
       "      <td>บางปะอิน</td>\n",
       "      <td>พระนครศรีอยุธยา</td>\n",
       "      <td>13160.0</td>\n",
       "      <td>261074</td>\n",
       "      <td>3403</td>\n",
       "      <td>20500000.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>446.75</td>\n",
       "      <td>16210.0</td>\n",
       "      <td>3-34(3)-1/18อย</td>\n",
       "      <td>กทม. และภาคกลาง</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140000225187</td>\n",
       "      <td>บริษัท โนเบิลวู้ด จำกัด</td>\n",
       "      <td>โนเบิลวู้ด</td>\n",
       "      <td>ทำไม้อัด และไม้ประสาน</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>เข้าโรงงานกระดาษบางปะอิน</td>\n",
       "      <td>บ้านเลน</td>\n",
       "      <td>บางปะอิน</td>\n",
       "      <td>พระนครศรีอยุธยา</td>\n",
       "      <td>13160.0</td>\n",
       "      <td>261074</td>\n",
       "      <td>3403</td>\n",
       "      <td>148580000.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>2416.08</td>\n",
       "      <td>16210.0</td>\n",
       "      <td>3-34(3)-2/18อย</td>\n",
       "      <td>กทม. และภาคกลาง</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   เลขทะเบียนโรงงาน                              ชื่อโรงงาน  ผู้ประกอบการ  \\\n",
       "0    20600006925518  ห้างหุ้นส่วนจำกัด บุญชูคอนกรีตผสมเสร็จ  บุญชูคอนกรีต   \n",
       "1    10140100125188                 บริษัท โนเบิลวู้ด จำกัด    โนเบิลวู้ด   \n",
       "2    10140000225187                 บริษัท โนเบิลวู้ด จำกัด    โนเบิลวู้ด   \n",
       "\n",
       "            ประกอบกิจการ เลขที่ หมู่  ซอย                       ถนน     ตำบล  \\\n",
       "0    ผลิตคอนกรีตผสมเสร็จ    NaN    5  NaN                       NaN  ชุมตาบง   \n",
       "1        ผลิตไม้วีเนียร์     66   11  NaN  เข้าโรงงานกระดาษบางปะอิน  บ้านเลน   \n",
       "2  ทำไม้อัด และไม้ประสาน     66   11  NaN  เข้าโรงงานกระดาษบางปะอิน  บ้านเลน   \n",
       "\n",
       "      อำเภอ          จังหวัด  ไปรษณีย์ โทรศัพท์ ประเภท      เงินทุน  คนงาน  \\\n",
       "0   ชุมตาบง        นครสวรรค์   60150.0      NaN   5801    6500000.0    5.0   \n",
       "1  บางปะอิน  พระนครศรีอยุธยา   13160.0   261074   3403   20500000.0   41.0   \n",
       "2  บางปะอิน  พระนครศรีอยุธยา   13160.0   261074   3403  148580000.0  197.0   \n",
       "\n",
       "    แรงม้า     TSIC    เลขทะเบียนเดิม             Area  \n",
       "0    95.00  23953.0  จ3-58(1)-69/51นว  กทม. และภาคกลาง  \n",
       "1   446.75  16210.0    3-34(3)-1/18อย  กทม. และภาคกลาง  \n",
       "2  2416.08  16210.0    3-34(3)-2/18อย  กทม. และภาคกลาง  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import diw data\n",
    "input_data_path = './diw/all/diw_client.xlsx'\n",
    "df_template = pd.read_excel(input_data_path)\n",
    "\n",
    "df = df_template.copy()\n",
    "\n",
    "# remove ผู้ประกอบการว่าง\n",
    "df = df.dropna(subset=['ผู้ประกอบการ'])\n",
    "\n",
    "# Clean data before extract\n",
    "pattern = r'บริษัท|จำกัด|ห้างหุ้นส่วน|สามัญนิติบุคคล|หนังสือบริคณห์สนธิ|มหาชน|หอการค้า|สมาคมการค้า|จังหวัด|\\([^\\(\\)]*\\)'\n",
    "df['ผู้ประกอบการ'] = df['ผู้ประกอบการ'].str.replace(pattern,'',regex=True).str.strip()\n",
    "\n",
    "# Sort data before extract\n",
    "sorter = ['กทม. และภาคกลาง','ภาคตะวันออก','ภาคตะวันตก','ภาคเหนือ','ภาคใต้','ภาคตะวันออกเฉียงเหนือ']\n",
    "\n",
    "df['Area'] = df['Area'].astype(\"category\")\n",
    "df['Area'] = df['Area'].cat.reorder_categories(sorter)\n",
    "df = df.sort_values(['Area']).reset_index(drop=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract dbd data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "1.ยังทำให้มันรอจบ event แล้วค่อยผ่านไปไม่ได้ \n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตัดอันที่ไม่จำเป็นออก เช่น log หรือ export file csv บางอัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import logging \n",
    "import re\n",
    "\n",
    "def create_log(log_name,log_output_path):\n",
    "    logger = logging.getLogger(log_name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    filehandler = logging.FileHandler(log_output_path)\n",
    "    filehandler.setFormatter(\n",
    "        logging.Formatter(\"%(asctime)s [%(levelname)s]  %(message)s\")\n",
    "    )\n",
    "    logger.addHandler(filehandler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def export_file(curr_arr,curr_idx,column_name,export_name,export_path):\n",
    "    curr_arr.append(curr_idx)\n",
    "    \n",
    "    dbd_df = pd.DataFrame(curr_arr,columns=column_name)\n",
    "    \n",
    "    dbd_df_file = f'{export_name}.csv'\n",
    "    dbd_df_path = f'{export_path}/{dbd_df_file}'\n",
    "\n",
    "    dbd_df.to_csv(dbd_df_path)\n",
    "\n",
    "async def main():\n",
    "\n",
    "    ############### Config ##################\n",
    "    # start_idx = 6610 \n",
    "    start_idx = 0\n",
    "    end_idx = len(df)-1\n",
    "\n",
    "    track_idx_logger_name = 'idx' \n",
    "    track_url_logger_name = 'url'\n",
    "    track_click_logger_name = 'click'\n",
    "    track_data_logger_name = 'data'\n",
    "\n",
    "    track_status_logger_name = 'status'\n",
    "\n",
    "    dbd_success_path = './dbd/success'\n",
    "    dbd_fail_path = './dbd/fail'\n",
    "\n",
    "    dbd_data_path = './dbd/data'\n",
    "\n",
    "    dbd_error_path = './dbd/error'\n",
    "    dbd_no_income_statement_path = './dbd/no_income_statement'\n",
    "    dbd_cannot_get_financial_statement_table_path = './dbd/cannot_get_financial_statement_table'\n",
    "    dbd_cannot_access_income_statement_path = './dbd/cannot_access_income_statement'\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    success_idx = []\n",
    "    fail_idx = []\n",
    "\n",
    "    data = []\n",
    "\n",
    "    error_idx = []\n",
    "    no_income_statement_idx = []\n",
    "    cannot_get_financial_statement_table_idx = []\n",
    "    cannot_access_income_statement_idx = []\n",
    "    \n",
    "\n",
    "    column_name = ['idx',\n",
    "                   'เลขทะเบียนนิติบุคคล',\n",
    "                   'เลขทะเบียนโรงงาน',\n",
    "                   'ชื่อนิติบุคคล',\n",
    "                   'งบกำไรขาดทุน',\n",
    "                   'ปี',\n",
    "                   'จำนวนเงิน',\n",
    "                   'การเปลี่ยนแปลง',\n",
    "                   'ประเภทนิติบุคคล',\n",
    "                   'สถานะนิติบุคคล',\n",
    "                   'วันที่จดทะเบียนจัดตั้ง',\n",
    "                   'ทุนจดทะเบียน',\n",
    "                   'เลขทะเบียนเดิม',\n",
    "                   'กลุ่มธุรกิจ',\n",
    "                   'ขนาดธุรกิจ',\n",
    "                   'ที่ตั้งสำนักงานแห่งใหญ่',\n",
    "                   'ที่ตั้งตรงกับสำนักงานใหญ่',\n",
    "                   'หาเจอ',\n",
    "                    ]\n",
    "    \n",
    "    idx_name = ['idx']\n",
    "\n",
    "    find_again_url = 'https://datawarehouse.dbd.go.th/searchJuristicInfo'\n",
    "\n",
    "    reg_province = r'(?<=จ\\.)\\s*[\\u0E00-\\u0e7f]+|กรุงเทพมหานคร'\n",
    "    reg_district = r'(?<=อ\\.)\\s*[\\u0E00-\\u0e7f]+|(?<=เขต)\\s*[\\u0E00-\\u0e7f]+'\n",
    "    reg_subdistrict = r'(?<=ต\\.)\\s*[\\u0E00-\\u0e7f]+|(?<=แขวง)\\s*[\\u0E00-\\u0e7f]+'\n",
    "\n",
    "    # Create log\n",
    "    num_dash = 100\n",
    "\n",
    "    track_idx_logger = create_log(f'{track_idx_logger_name}',f'./log/{track_idx_logger_name}.log')\n",
    "    track_url_logger = create_log(f'{track_url_logger_name}',f'./log/{track_url_logger_name}.log')\n",
    "    track_click_logger = create_log(f'{track_click_logger_name}',f'./log/{track_click_logger_name}.log')\n",
    "    track_data_logger = create_log(f'{track_data_logger_name}',f'./log/{track_data_logger_name}.log')\n",
    "    track_status_logger = create_log(f'{track_status_logger_name}',f'./log/{track_status_logger_name}.log')\n",
    "\n",
    "    async with async_playwright() as playwright:\n",
    "        # Launch a browser\n",
    "        browser = await playwright.chromium.launch(headless=False) \n",
    "\n",
    "        # Create a new page\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        start_url = 'https://datawarehouse.dbd.go.th/index'\n",
    "\n",
    "        previous_url = start_url\n",
    "        \n",
    "        await page.goto(start_url)\n",
    "        track_url_logger.debug(f'Completed goto {start_url}')\n",
    "\n",
    "        # กด button ปิด , ยอมรับทั้งหมด\n",
    "        await page.locator('//button[text()=\"ปิด\"]').click() \n",
    "        track_click_logger.debug('Completed Click \"ปิด\"')\n",
    "        \n",
    "        await page.locator('//button[text()=\"ยอมรับทั้งหมด\"]').click()\n",
    "        track_click_logger.debug('Completed Click \"ยอมรับทั้งหมด\"')\n",
    "\n",
    "        # Loop ข้อมูลทีละ idx \n",
    "        for idx in range(start_idx,end_idx+1):\n",
    "            broken_web = True\n",
    "            extract_income_statement = False\n",
    "            exitLoop = False\n",
    "            \n",
    "            # Run again when broken_web\n",
    "            while broken_web:\n",
    "                # ถ้า run แล้วเว็บไม่มีปัญหา\n",
    "                try:\n",
    "                    track_idx_logger.debug(f'{idx = }')\n",
    "                    track_url_logger.debug(f'{idx = }')\n",
    "                    track_click_logger.debug(f'{idx = }')\n",
    "                    track_data_logger.debug(f'{idx = }')\n",
    "                    track_status_logger.debug(f'{idx = }')\n",
    "\n",
    "                    factory_id = df.loc[idx,'เลขทะเบียนโรงงาน']\n",
    "\n",
    "                    client = df.loc[idx,'ผู้ประกอบการ'].strip()\n",
    "                    province = df.loc[idx,'จังหวัด'].strip()\n",
    "                    district = df.loc[idx,'อำเภอ'].strip()\n",
    "                    subdistrict = df.loc[idx,'ตำบล'].strip()\n",
    "\n",
    "                    # กรณี search ครั้งแรก\n",
    "                    if idx==start_idx:\n",
    "                        input = page.get_by_placeholder('ค้นหาด้วยชื่อหรือเลขทะเบียนนิติบุคคล รหัสประเภทธุรกิจ ชื่อหรือคำอธิบายประเภทธุรกิจ')\n",
    "                    # กรณี search ครั้งต่อไป\n",
    "                    else:\n",
    "                        input = page.get_by_placeholder('ค้นหาด้วยชื่อหรือเลขทะเบียนนิติบุคคล')\n",
    "\n",
    "                    await input.fill(client)\n",
    "                    await input.press('Enter') \n",
    "\n",
    "                    track_url_logger.debug(f'Completed fill {client = }')\n",
    "\n",
    "                    current_url = page.url\n",
    "\n",
    "                    track_url_logger.debug(f'{previous_url = }')\n",
    "                    track_url_logger.debug(f'{current_url = }')\n",
    "\n",
    "                    track_status_logger.debug(f'Completed fill {client = } & Press \"Enter\"')\n",
    "                    \n",
    "                    # กรณี search ครั้งเดียวเจอ , url เปลี่ยนตลอด \n",
    "                    if current_url != find_again_url and current_url != previous_url:\n",
    "                        \n",
    "                        parent = \"//*[@id='companyProfileTab1']/div[2]/div[1]/div[1]/div/div/div\"\n",
    "\n",
    "                        corporation_type = await page.locator(f\"{parent}/div[text()='ประเภทนิติบุคคล']/following-sibling::div[1]\").text_content()\n",
    "\n",
    "                        corporation_status = await page.locator(f\"{parent}/div[text()='สถานะนิติบุคคล']/following-sibling::div[1]\").text_content()\n",
    "\n",
    "                        registration_date = await page.locator(f\"{parent}/div[text()='วันที่จดทะเบียนจัดตั้ง']/following-sibling::div[1]\").text_content()\n",
    "\n",
    "                        registered_capital = await page.locator(f\"{parent}/div[text()='ทุนจดทะเบียน']/following-sibling::div[1]\").text_content()\n",
    "\n",
    "                        old_corporation_id = await page.locator(f\"{parent}/div[text()='เลขทะเบียนเดิม']/following-sibling::div[1]\").text_content()\n",
    "\n",
    "                        business_type = await page.locator(f\"{parent}/div[text()='กลุ่มธุรกิจ']/following-sibling::div[1]\").text_content()\n",
    "\n",
    "                        business_size = await page.locator(f\"{parent}/div[text()='ขนาดธุรกิจ']/following-sibling::div[1]\").text_content()\n",
    "\n",
    "                        center_location = await page.locator(f\"{parent}/div[text()='ที่ตั้งสำนักงานแห่งใหญ่']/following-sibling::div[1]\").text_content()\n",
    "\n",
    "                        found = 'Yes'\n",
    "\n",
    "                        # check ที่ตั้งสำนักงานใหญ่ \n",
    "                        if province == re.findall(reg_province,center_location)[0].strip() and \\\n",
    "                            district == re.findall(reg_district,center_location)[0].strip() and \\\n",
    "                            subdistrict == re.findall(reg_subdistrict,center_location)[0].strip():\n",
    "                            same_center_location = 'Yes'\n",
    "\n",
    "                        else:\n",
    "                            same_center_location = 'No'\n",
    "\n",
    "                        await page.locator('//span[text()=\"ข้อมูลงบการเงิน\"]').click()\n",
    "                        track_click_logger.debug('Completed Click \"ข้อมูลงบการเงิน\"')\n",
    "\n",
    "                        # Define Boolean broken_web\n",
    "                        broken_web = False\n",
    "\n",
    "                        # check ว่ามีข้อมูลงบกำไรขาดทุนไหม ถ้ามีดึงมันมา \n",
    "                        try:\n",
    "                            await page.locator('//span[text()=\"งบกำไรขาดทุน\"]').click()\n",
    "                            track_click_logger.debug('Completed Click \"งบกำไรขาดทุน\"')\n",
    "    \n",
    "                            track_status_logger.debug(f'Has income statement')\n",
    "\n",
    "                            # check ว่าสามารถดึงงบกำไรขาดทุนมาได้ไหม ถ้าได้ดึงมาปกติ ถ้าไม่ได้ให้ดึงอีกครั้ง\n",
    "                            while not extract_income_statement:\n",
    "                                try:\n",
    "                                    # locate ไปที่ income statement table \n",
    "                                    table_loc = page.locator(\"(//div[@class='table-responsive'])[1]\")\n",
    "                                    table = BeautifulSoup(await table_loc.inner_html(), 'html.parser')\n",
    "                                    track_data_logger.debug(f'Completed Access table')\n",
    "\n",
    "                                    # current year - 1 นับถอยหลังไป 5 \n",
    "                                    year_loc = page.locator(\"//table[@class='table table-hover text-end table-fixed']/thead/tr[1]\")\n",
    "                                    year = BeautifulSoup(await year_loc.inner_html(), 'html.parser')\n",
    "                                    track_data_logger.debug(f'Completed Access year')\n",
    "                                \n",
    "                                    years = []\n",
    "\n",
    "                                    for y in year.find_all('th'):\n",
    "                                        years.append(y.text)\n",
    "\n",
    "                                    years = years[1:]\n",
    "\n",
    "                                    corporation_id = await page.locator(\"//h4[contains(text(),'เลขทะเบียนนิติบุคคล')]\").text_content()\n",
    "                                    corporation_id = corporation_id.split(':')[1]\n",
    "\n",
    "                                    corporation_name = await page.locator(\"//h3[contains(text(),'ชื่อนิติบุคคล')]\").text_content()\n",
    "                                    corporation_name = corporation_name.split(':')[1]\n",
    "\n",
    "                                    track_status_logger.debug(f'can_get_financial_statement_table')\n",
    "\n",
    "                                    for body in table.find_all('tbody'):\n",
    "                                        for rows in body.find_all('tr'):\n",
    "                                            for income_states in rows.find_all('th'):\n",
    "                                                # check ว่าสามารถดึงงบกำไรขาดทุนมาได้ไหม ถ้าได้ดึงมาปกติ ถ้าไม่ได้ให้ดึงอีกครั้ง\n",
    "                                                if income_states.text == 'รายได้หลัก':\n",
    "                                                    # Define Boolean extract_income_statement\n",
    "                                                    extract_income_statement = True\n",
    "                                                \n",
    "                                                if extract_income_statement:\n",
    "                                                    for i,year_state in enumerate(years):\n",
    "                                                        values = rows.find_all('td')[2*i:2*(i+1)]\n",
    "                                                        amount = values[0].text\n",
    "                                                        change_amount = values[1].text\n",
    "\n",
    "                                                        data.append([idx,\n",
    "                                                                    corporation_id,\n",
    "                                                                    factory_id,\n",
    "                                                                    corporation_name,\n",
    "                                                                    income_states.text,\n",
    "                                                                    year_state,\n",
    "                                                                    amount,\n",
    "                                                                    change_amount,\n",
    "                                                                    corporation_type,\n",
    "                                                                    corporation_status,\n",
    "                                                                    registration_date,\n",
    "                                                                    registered_capital,\n",
    "                                                                    old_corporation_id,\n",
    "                                                                    business_type,\n",
    "                                                                    business_size,\n",
    "                                                                    center_location,\n",
    "                                                                    same_center_location,\n",
    "                                                                    found])\n",
    "\n",
    "                                                else:\n",
    "                                                    exitLoop = True\n",
    "                                                    break\n",
    "                                            if exitLoop:\n",
    "                                                break\n",
    "                                        if exitLoop:\n",
    "                                            break\n",
    "\n",
    "                                    if extract_income_statement:\n",
    "                                        track_data_logger.debug(f'Completed Extract Income Statement')\n",
    "                                        \n",
    "                                        # Export success_idx\n",
    "                                        export_file(success_idx,\n",
    "                                                    idx,\n",
    "                                                    idx_name,\n",
    "                                                    f'success_idx {start_idx}',\n",
    "                                                    dbd_success_path)\n",
    "                                        \n",
    "                                        track_status_logger.debug(f'can_access_income_statement')\n",
    "\n",
    "                                    else:\n",
    "                                        # Export cannot_access_income_statement_idx\n",
    "                                        export_file(cannot_access_income_statement_idx,\n",
    "                                                idx,\n",
    "                                                idx_name,\n",
    "                                                f'cannot_access_income_statement_idx {start_idx}'\n",
    "                                                ,dbd_cannot_access_income_statement_path)\n",
    "                                        \n",
    "                                        # Export fail_idx\n",
    "                                        export_file(fail_idx,\n",
    "                                                    idx,\n",
    "                                                    idx_name,\n",
    "                                                    f'fail_idx {start_idx}'\n",
    "                                                    ,dbd_fail_path)\n",
    "                                        \n",
    "                                        track_status_logger.error(f'cannot_access_income_statement')\n",
    "\n",
    "                                except:\n",
    "                                    # Export cannot_get_financial_statement_table_idx\n",
    "                                    export_file(cannot_get_financial_statement_table_idx,\n",
    "                                                idx,\n",
    "                                                idx_name,\n",
    "                                                f'cannot_get_financial_statement_table_idx {start_idx}'\n",
    "                                                ,dbd_cannot_get_financial_statement_table_path)\n",
    "\n",
    "                                    # Export fail_idx\n",
    "                                    export_file(fail_idx,\n",
    "                                                idx,\n",
    "                                                idx_name,\n",
    "                                                f'fail_idx {start_idx}'\n",
    "                                                ,dbd_fail_path)\n",
    "                                    \n",
    "                                    track_status_logger.error(f'cannot_get_financial_statement_table')\n",
    "\n",
    "                        except:\n",
    "                            # Export no_income_statement_idx\n",
    "                            export_file(no_income_statement_idx,\n",
    "                                        idx,\n",
    "                                        idx_name,\n",
    "                                        f'no_income_statement_idx {start_idx}'\n",
    "                                        ,dbd_no_income_statement_path)\n",
    "\n",
    "                            # Export success_idx\n",
    "                            export_file(success_idx,\n",
    "                                        idx,\n",
    "                                        idx_name,\n",
    "                                        f'success_idx {start_idx}',\n",
    "                                        dbd_success_path)\n",
    "                            \n",
    "                            data.append([idx,\n",
    "                                        '',\n",
    "                                        factory_id,\n",
    "                                        '',\n",
    "                                        '',\n",
    "                                        '',\n",
    "                                        '',\n",
    "                                        '',\n",
    "                                        corporation_type,\n",
    "                                        corporation_status,\n",
    "                                        registration_date,\n",
    "                                        registered_capital,\n",
    "                                        old_corporation_id,\n",
    "                                        business_type,\n",
    "                                        business_size,\n",
    "                                        center_location,\n",
    "                                        same_center_location,\n",
    "                                        found])\n",
    "                            \n",
    "                            track_status_logger.error(f'No income statement')\n",
    "                            \n",
    "                    # กรณี search ครั้งเดียวไม่เจอ , url จะไม่เปลี่ยน \n",
    "                    else:\n",
    "                        data.append([idx]+['']+[factory_id]+['']*(len(column_name)-3)+['No'])\n",
    "\n",
    "                        # Export success_idx\n",
    "                        export_file(success_idx,\n",
    "                                    idx,\n",
    "                                    idx_name,\n",
    "                                    f'success_idx {start_idx}',\n",
    "                                    dbd_success_path)\n",
    "\n",
    "                    previous_url = current_url\n",
    "\n",
    "                    # Export dbd data (Error this definitely)\n",
    "                    dbd_df = pd.DataFrame(data,columns=column_name)\n",
    "                    \n",
    "                    dbd_df_file = f'dbd_client {start_idx}.csv'\n",
    "                    dbd_df_path = f'{dbd_data_path}/{dbd_df_file}'\n",
    "\n",
    "                    dbd_df.to_csv(dbd_df_path)\n",
    "\n",
    "                    if extract_income_statement:\n",
    "                        track_status_logger.info('Success') \n",
    "                    else:\n",
    "                        track_status_logger.error('Fail') \n",
    "                    \n",
    "                    track_idx_logger.debug('-'*num_dash)\n",
    "                    track_url_logger.debug('-'*num_dash)\n",
    "                    track_click_logger.debug('-'*num_dash)\n",
    "                    track_data_logger.debug('-'*num_dash)\n",
    "                    track_status_logger.debug('-'*num_dash)\n",
    "\n",
    "                # ถ้า run แล้วเว็บมีปัญหา\n",
    "                except:                    \n",
    "                    # Export error_idx\n",
    "                    export_file(error_idx,\n",
    "                                idx,\n",
    "                                idx_name,\n",
    "                                f'error_idx {start_idx}',\n",
    "                                dbd_error_path)        \n",
    "\n",
    "                    # Export fail_idx\n",
    "                    export_file(fail_idx,\n",
    "                                idx,\n",
    "                                idx_name,\n",
    "                                f'fail_idx {start_idx}',\n",
    "                                dbd_fail_path)\n",
    "                    \n",
    "                    track_status_logger.error('Fail') \n",
    "            \n",
    "                    track_idx_logger.debug('-'*num_dash)\n",
    "                    track_url_logger.debug('-'*num_dash)\n",
    "                    track_click_logger.debug('-'*num_dash)\n",
    "                    track_data_logger.debug('-'*num_dash)\n",
    "                    track_status_logger.debug('-'*num_dash)\n",
    "\n",
    "        await browser.close() \n",
    "            \n",
    "        end_time = datetime.now()\n",
    "        diff_time = end_time - start_time\n",
    "        print(diff_time)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
